{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion, MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2910e6e8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Exploration\n",
    "% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "image = mnist.test.images[1].reshape([28,28])\n",
    "plt.imshow(image)\n",
    "label = mnist.test.labels[1]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data volume 10000\n",
      "The train data volume 55000\n"
     ]
    }
   ],
   "source": [
    "# len of training and testing data\n",
    "print(\"The test data volume\", len(mnist.test.images))\n",
    "print(\"The train data volume\", len(mnist.train.images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 10000\n",
      "Training 55000\n"
     ]
    }
   ],
   "source": [
    "# len of labels \n",
    "print(\"Testing\", len(mnist.test.labels))\n",
    "print(\"Training\", len(mnist.train.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # TODO : Layer 1 - 28*28*1 to 14*14*32 \n",
    "    #conv1\n",
    "    \n",
    "    c1 = conv2d(x, weights['wc1'],biases['bc1'], 1)\n",
    "    \n",
    "    #maxpoolbc1\n",
    "    m1 = maxpool2d(c1,2)\n",
    "    \n",
    "    \n",
    "    # TODO: Layer 2 - 14*14*32 to 7*7*64\n",
    "    #conv2\n",
    "    c2 = conv2d(m1, weights['wc2'],biases['bc2'],1)\n",
    "    \n",
    "    #maxpool\n",
    "    m2 = maxpool2d(c2, k=2)\n",
    "    \n",
    "    # TODO: Fully connected layer - 7*7*64 to 1024\n",
    "    #reshape\n",
    "    fc1 = tf.reshape(m2,[-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 =tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    #multiply and add bias \n",
    "    # relu activation\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 79147.5859 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch   2 - Loss: 71141.1406 Validation Accuracy: 0.105469\n",
      "Epoch  1, Batch   3 - Loss: 55610.8906 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch   4 - Loss: 45595.3125 Validation Accuracy: 0.105469\n",
      "Epoch  1, Batch   5 - Loss: 47477.4336 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   6 - Loss: 40763.3672 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   7 - Loss: 38953.6172 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   8 - Loss: 39898.5273 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch   9 - Loss: 38906.8242 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch  10 - Loss: 35654.6562 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch  11 - Loss: 29960.7500 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch  12 - Loss: 31533.2852 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch  13 - Loss: 30077.7617 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch  14 - Loss: 30676.0703 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch  15 - Loss: 27617.1719 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch  16 - Loss: 25547.4883 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch  17 - Loss: 27374.8047 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch  18 - Loss: 25581.1445 Validation Accuracy: 0.132812\n",
      "Epoch  1, Batch  19 - Loss: 22806.6367 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch  20 - Loss: 25660.9824 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch  21 - Loss: 21910.1699 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  22 - Loss: 25196.0312 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  23 - Loss: 20690.8770 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch  24 - Loss: 20508.6641 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch  25 - Loss: 22289.7070 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch  26 - Loss: 20282.3867 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  27 - Loss: 19617.9570 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  28 - Loss: 20014.8477 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  29 - Loss: 18868.6211 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  30 - Loss: 18216.2129 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  31 - Loss: 16763.2305 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  32 - Loss: 18021.6211 Validation Accuracy: 0.207031\n",
      "Epoch  1, Batch  33 - Loss: 18835.9941 Validation Accuracy: 0.207031\n",
      "Epoch  1, Batch  34 - Loss: 16290.6299 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  35 - Loss: 16749.3242 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  36 - Loss: 16028.4375 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  37 - Loss: 16246.3252 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  38 - Loss: 15456.3301 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  39 - Loss: 16249.1250 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  40 - Loss: 12587.5088 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  41 - Loss: 16005.6504 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  42 - Loss: 17285.4180 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  43 - Loss: 13472.3926 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  44 - Loss: 14015.5898 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  45 - Loss: 13428.5166 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  46 - Loss: 11251.2168 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  47 - Loss: 15219.9268 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  48 - Loss: 14539.9629 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  49 - Loss: 11898.4980 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  50 - Loss: 13104.5498 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  51 - Loss: 12997.0830 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  52 - Loss: 13736.4150 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  53 - Loss:  9613.6191 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  54 - Loss: 11100.3164 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  55 - Loss: 11470.9238 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  56 - Loss: 11201.8359 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  57 - Loss:  9566.0273 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  58 - Loss: 10421.0059 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  59 - Loss: 11500.1162 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  60 - Loss: 10859.5859 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  61 - Loss:  9638.8037 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  62 - Loss: 11795.1719 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  63 - Loss: 11182.7793 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  64 - Loss:  9508.9395 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  65 - Loss: 10991.1582 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  66 - Loss:  9881.8848 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  67 - Loss: 10628.3203 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  68 - Loss:  8416.3232 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  69 - Loss:  7494.8457 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  70 - Loss:  9433.5400 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  71 - Loss:  9914.5771 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  72 - Loss:  8311.2734 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  73 - Loss:  8648.0078 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  74 - Loss:  9927.8672 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  75 - Loss:  8660.9629 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  76 - Loss:  7915.4697 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  77 - Loss:  8065.8525 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  78 - Loss:  8757.9688 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  79 - Loss: 10012.7402 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  80 - Loss:  8468.0215 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  81 - Loss:  8117.7900 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  82 - Loss:  8462.9668 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  83 - Loss:  7566.9404 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  84 - Loss:  7243.1147 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  85 - Loss:  6407.4375 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  86 - Loss:  8684.1230 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  87 - Loss:  9384.0371 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  88 - Loss:  7745.1953 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  89 - Loss:  8229.6934 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  90 - Loss:  7901.1592 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  91 - Loss:  7204.7622 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  92 - Loss:  6213.0068 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  93 - Loss:  6749.2021 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  94 - Loss:  6519.8628 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  95 - Loss:  6328.2461 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  96 - Loss:  7301.7461 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  97 - Loss:  7285.4673 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  98 - Loss:  7593.4927 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  99 - Loss:  6896.6484 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch 100 - Loss:  7875.9077 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch 101 - Loss:  7693.2754 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch 102 - Loss:  6378.2666 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch 103 - Loss:  5675.4829 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch 104 - Loss:  5649.2295 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch 105 - Loss:  6174.3691 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch 106 - Loss:  4918.1562 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch 107 - Loss:  5627.9473 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch 108 - Loss:  7464.9272 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch 109 - Loss:  5888.9473 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch 110 - Loss:  7277.8574 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch 111 - Loss:  6251.0098 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch 112 - Loss:  7414.1953 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch 113 - Loss:  5349.3711 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch 114 - Loss:  6311.0488 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch 115 - Loss:  6843.8633 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch 116 - Loss:  6017.6685 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch 117 - Loss:  6950.8008 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch 118 - Loss:  6991.7852 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch 119 - Loss:  6076.4834 Validation Accuracy: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 120 - Loss:  5662.2910 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch 121 - Loss:  5095.5771 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch 122 - Loss:  5507.7559 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch 123 - Loss:  4957.9121 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 124 - Loss:  5613.2539 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 125 - Loss:  6157.0869 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 126 - Loss:  5267.4570 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch 127 - Loss:  5396.6084 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 128 - Loss:  5682.5454 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 129 - Loss:  6914.8521 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 130 - Loss:  5904.4834 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 131 - Loss:  6169.2188 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 132 - Loss:  6195.6138 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 133 - Loss:  4686.9297 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 134 - Loss:  5387.3667 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 135 - Loss:  4881.6992 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 136 - Loss:  4165.0952 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 137 - Loss:  5062.2744 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 138 - Loss:  4585.5522 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 139 - Loss:  6538.5952 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 140 - Loss:  4387.5449 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 141 - Loss:  5337.7529 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 142 - Loss:  5393.9863 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 143 - Loss:  4829.1743 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 144 - Loss:  6495.0654 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 145 - Loss:  3581.7036 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 146 - Loss:  4944.6118 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 147 - Loss:  5014.0186 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 148 - Loss:  5511.4668 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 149 - Loss:  5093.3247 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 150 - Loss:  3786.8281 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 151 - Loss:  4950.7568 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 152 - Loss:  4275.4043 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 153 - Loss:  4680.7217 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 154 - Loss:  5023.5010 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 155 - Loss:  3433.2317 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 156 - Loss:  3847.8289 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 157 - Loss:  4508.7705 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 158 - Loss:  5060.6094 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 159 - Loss:  4653.1826 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 160 - Loss:  5679.0264 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 161 - Loss:  4411.5220 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 162 - Loss:  4972.8467 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 163 - Loss:  5496.5674 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 164 - Loss:  5667.4355 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 165 - Loss:  3458.0962 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 166 - Loss:  4491.5586 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 167 - Loss:  5018.4502 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 168 - Loss:  4023.8691 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 169 - Loss:  4369.4502 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 170 - Loss:  3397.6897 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 171 - Loss:  4539.5049 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 172 - Loss:  4327.3125 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 173 - Loss:  3579.9500 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 174 - Loss:  4319.5825 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 175 - Loss:  4296.1851 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 176 - Loss:  4142.8467 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 177 - Loss:  5420.5493 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 178 - Loss:  3821.7478 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 179 - Loss:  3900.9822 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 180 - Loss:  5525.8262 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 181 - Loss:  3682.7571 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 182 - Loss:  3277.3130 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 183 - Loss:  4043.5032 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 184 - Loss:  4475.5312 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 185 - Loss:  4235.6919 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 186 - Loss:  3677.7256 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 187 - Loss:  3535.7661 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 188 - Loss:  3887.5222 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 189 - Loss:  3930.9465 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 190 - Loss:  4120.4448 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 191 - Loss:  5102.5176 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 192 - Loss:  3771.4907 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 193 - Loss:  4058.0410 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 194 - Loss:  4180.5674 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 195 - Loss:  3587.1147 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 196 - Loss:  3413.7207 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 197 - Loss:  3015.1157 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 198 - Loss:  3685.6604 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 199 - Loss:  2594.7017 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 200 - Loss:  3796.1353 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 201 - Loss:  3254.5723 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 202 - Loss:  3035.8552 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 203 - Loss:  3953.8918 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 204 - Loss:  2905.5703 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 205 - Loss:  3395.5312 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 206 - Loss:  2997.5884 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 207 - Loss:  2983.4536 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 208 - Loss:  3102.1006 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 209 - Loss:  3071.0176 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 210 - Loss:  2764.7432 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 211 - Loss:  2575.0020 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 212 - Loss:  3034.7236 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 213 - Loss:  4012.1704 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 214 - Loss:  3365.8086 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 215 - Loss:  3231.5410 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 216 - Loss:  3947.6736 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 217 - Loss:  3613.7368 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 218 - Loss:  2833.3010 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 219 - Loss:  2976.0850 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 220 - Loss:  2997.6636 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 221 - Loss:  3580.8015 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 222 - Loss:  3648.7166 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 223 - Loss:  4007.0886 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 224 - Loss:  3928.2939 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 225 - Loss:  3527.9824 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 226 - Loss:  2593.7976 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 227 - Loss:  3428.9172 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 228 - Loss:  3350.7163 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 229 - Loss:  3458.9863 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 230 - Loss:  2870.7461 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 231 - Loss:  3628.8628 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 232 - Loss:  3180.1055 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 233 - Loss:  2169.6021 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 234 - Loss:  3199.7493 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 235 - Loss:  3236.0952 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 236 - Loss:  2659.6875 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 237 - Loss:  3619.0984 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 238 - Loss:  3384.2031 Validation Accuracy: 0.691406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 239 - Loss:  3155.4722 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 240 - Loss:  2441.1570 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 241 - Loss:  3474.0967 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 242 - Loss:  1993.9653 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 243 - Loss:  2823.5044 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 244 - Loss:  1688.4482 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 245 - Loss:  3241.8887 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 246 - Loss:  3376.0859 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 247 - Loss:  2473.9473 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 248 - Loss:  2924.3323 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 249 - Loss:  2552.2930 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 250 - Loss:  2330.9238 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 251 - Loss:  2978.2253 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 252 - Loss:  2406.5103 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 253 - Loss:  3336.5647 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 254 - Loss:  2157.3950 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 255 - Loss:  2821.7422 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 256 - Loss:  3495.2007 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 257 - Loss:  3424.5073 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 258 - Loss:  3317.0972 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 259 - Loss:  2822.9102 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 260 - Loss:  2544.0491 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 261 - Loss:  2864.6025 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 262 - Loss:  2654.0664 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 263 - Loss:  2690.2554 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 264 - Loss:  2771.5464 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 265 - Loss:  3320.5974 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 266 - Loss:  2699.0286 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 267 - Loss:  3148.7280 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 268 - Loss:  2061.8110 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 269 - Loss:  3518.0193 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 270 - Loss:  2556.2136 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 271 - Loss:  2746.6074 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 272 - Loss:  2907.0991 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 273 - Loss:  2309.2324 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 274 - Loss:  2421.1626 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 275 - Loss:  2484.7969 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 276 - Loss:  2584.7832 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 277 - Loss:  2369.7107 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 278 - Loss:  2707.2842 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 279 - Loss:  2516.7935 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 280 - Loss:  3174.9783 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 281 - Loss:  2867.4832 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 282 - Loss:  2797.9412 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 283 - Loss:  1640.7075 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 284 - Loss:  2830.9646 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 285 - Loss:  2698.4648 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 286 - Loss:  2164.1685 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 287 - Loss:  2068.7981 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 288 - Loss:  2451.5298 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 289 - Loss:  3486.4980 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 290 - Loss:  2879.4585 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 291 - Loss:  2537.7168 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 292 - Loss:  2067.0811 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 293 - Loss:  1995.8536 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 294 - Loss:  3615.4883 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 295 - Loss:  1886.1533 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 296 - Loss:  2834.8086 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 297 - Loss:  2475.8804 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 298 - Loss:  2835.4292 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 299 - Loss:  1872.2417 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 300 - Loss:  1964.3441 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 301 - Loss:  3027.0759 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 302 - Loss:  2959.5400 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 303 - Loss:  2261.1152 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 304 - Loss:  1915.5322 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 305 - Loss:  2349.3003 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 306 - Loss:  2765.5393 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 307 - Loss:  2036.2151 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 308 - Loss:  2491.2312 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 309 - Loss:  2955.8643 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 310 - Loss:  2103.8350 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 311 - Loss:  1875.8445 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 312 - Loss:  2259.3130 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 313 - Loss:  2020.9836 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 314 - Loss:  2531.5642 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 315 - Loss:  2204.2212 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 316 - Loss:  2900.7751 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 317 - Loss:  2744.9819 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 318 - Loss:  2288.0671 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 319 - Loss:  2399.4297 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 320 - Loss:  1816.4380 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 321 - Loss:  2452.7939 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 322 - Loss:  2185.7734 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 323 - Loss:  2123.7085 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 324 - Loss:  2139.1819 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 325 - Loss:  2386.3926 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 326 - Loss:  2567.3750 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 327 - Loss:  2508.6819 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 328 - Loss:  2033.5728 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 329 - Loss:  2345.3340 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 330 - Loss:  2260.3806 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 331 - Loss:  2627.8643 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 332 - Loss:  2562.3232 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 333 - Loss:  2697.0811 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 334 - Loss:  1578.5468 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 335 - Loss:  2800.8096 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 336 - Loss:  2249.7397 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 337 - Loss:  1920.5334 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 338 - Loss:  2064.2927 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 339 - Loss:  1644.0073 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 340 - Loss:  3152.6196 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 341 - Loss:  2640.3379 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 342 - Loss:  2715.3879 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 343 - Loss:  2246.8027 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 344 - Loss:  2479.5532 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 345 - Loss:  2030.9917 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 346 - Loss:  2529.4360 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 347 - Loss:  1962.1940 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 348 - Loss:  2416.9910 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 349 - Loss:  2684.4438 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 350 - Loss:  1968.8298 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 351 - Loss:  2243.5312 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 352 - Loss:  1313.5598 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 353 - Loss:  2378.9077 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 354 - Loss:  2548.4575 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 355 - Loss:  2476.2959 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 356 - Loss:  2686.5186 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 357 - Loss:  2115.9346 Validation Accuracy: 0.714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 358 - Loss:  2450.3008 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 359 - Loss:  2392.5293 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 360 - Loss:  1772.6821 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 361 - Loss:  2023.9775 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 362 - Loss:  1973.6666 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 363 - Loss:  1396.9231 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 364 - Loss:  2081.5742 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 365 - Loss:  1922.9619 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 366 - Loss:  2656.0483 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 367 - Loss:  1615.4546 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 368 - Loss:  2065.1042 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 369 - Loss:  1946.8922 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 370 - Loss:  2140.1763 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 371 - Loss:  1612.7471 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 372 - Loss:  2553.8989 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 373 - Loss:  2443.2944 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 374 - Loss:  1647.5994 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 375 - Loss:  2500.5264 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 376 - Loss:  1755.9534 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 377 - Loss:  1307.3601 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 378 - Loss:  2173.0310 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 379 - Loss:  1944.1270 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 380 - Loss:  1925.3011 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 381 - Loss:  1872.6445 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 382 - Loss:  2444.2749 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 383 - Loss:  2177.3184 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 384 - Loss:  1914.1655 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 385 - Loss:  1553.9034 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 386 - Loss:  1778.4061 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 387 - Loss:  2712.2046 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 388 - Loss:  1191.3096 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 389 - Loss:  2474.8015 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 390 - Loss:  2460.3179 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 391 - Loss:  2155.5103 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 392 - Loss:  2037.0907 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 393 - Loss:  1935.5377 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 394 - Loss:  1467.6504 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 395 - Loss:  1482.0275 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 396 - Loss:  1643.0999 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 397 - Loss:  1709.6062 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 398 - Loss:  2212.1895 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 399 - Loss:  1944.6553 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 400 - Loss:  1908.9401 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 401 - Loss:  1888.1979 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 402 - Loss:  1968.3701 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 403 - Loss:  2278.9170 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 404 - Loss:  2435.3447 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 405 - Loss:  2334.9995 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 406 - Loss:  3205.5737 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 407 - Loss:  1501.9482 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 408 - Loss:  1950.5154 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 409 - Loss:  2042.7031 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 410 - Loss:  1989.7606 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 411 - Loss:  2154.1514 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 412 - Loss:  2155.0193 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 413 - Loss:  2413.7793 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 414 - Loss:  2120.5649 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 415 - Loss:  1952.1033 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 416 - Loss:  2047.3398 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 417 - Loss:  1901.0884 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 418 - Loss:  1828.7368 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 419 - Loss:  1917.6877 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 420 - Loss:  2233.9656 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 421 - Loss:  1646.1932 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 422 - Loss:  2293.1982 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 423 - Loss:  2187.5298 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 424 - Loss:  1797.0549 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 425 - Loss:  1995.1887 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 426 - Loss:  2345.5591 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 427 - Loss:  1191.3431 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 428 - Loss:  1564.2032 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 429 - Loss:  2286.5349 Validation Accuracy: 0.722656\n",
      "Testing Accuracy: 0.72265625\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "            \n",
    "            \n",
    "     # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "            x: mnist.test.images[:test_valid_size],\n",
    "            y: mnist.test.labels[:test_valid_size],\n",
    "            keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
